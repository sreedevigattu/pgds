{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXsu8MxUVAKT"
      },
      "source": [
        "## Importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "kXr4Cxh2VAKZ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Eq-7JCT6VAKa"
      },
      "outputs": [],
      "source": [
        "import spacy \n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ItxQ587VVAKb"
      },
      "source": [
        "### Read reviews data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "q1pr6bbsVAKb"
      },
      "outputs": [],
      "source": [
        "# Load the Samsung.txt dataset\n",
        "con=open(\"../data/Samsung.txt\",'r', encoding=\"utf-8\")\n",
        "samsung_reviews=con.read()\n",
        "con.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "f4GyRJMEVAKb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "46355"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(samsung_reviews.split(\"\\n\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fU4ZvurwVAKc"
      },
      "source": [
        "### Dataset is a text file where each review is in a new line"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "bPT-wYC2VAKd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[\"I feel so LUCKY to have found this used (phone to us & not used hard at all), phone on line from someone who upgraded and sold this one. My Son liked his old one that finally fell apart after 2.5+ years and didn't want an upgrade!! Thank you Seller, we really appreciate it & your honesty re: said used phone.I recommend this seller very highly & would but from them again!!\",\n",
              " 'nice phone, nice up grade from my pantach revue. Very clean set up and easy set up. never had an android phone but they are fantastic to say the least. perfect size for surfing and social media. great phone samsung',\n",
              " 'Very pleased',\n",
              " 'It works good but it goes slow sometimes but its a very good phone I love it']"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "samsung_reviews.split(\"\\n\")[0:4]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUi5gE7WVAKd"
      },
      "source": [
        "### Will our hypothesis hold on real world data? `Product features---POS_NOUN`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "yUx96iRtVAKg"
      },
      "outputs": [],
      "source": [
        "review1=samsung_reviews.split(\"\\n\")[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKt6ZNPnVAKg"
      },
      "source": [
        "### Lets do nlp parse on part of one review in our dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "gOCZxFp_VAKh"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I feel so LUCKY to have found this used (phone to us & not used hard at all), phone on line from someone who upgraded and sold this one. My Son liked his old one that finally fell apart after 2.5+ years and didn't want an upgrade!! Thank you Seller, we really appreciate it & your honesty re: said used phone.I recommend this seller very highly & would but from them again!!\n",
            "I -- PRON\n",
            "feel -- VERB\n",
            "so -- ADV\n",
            "LUCKY -- ADJ\n",
            "to -- PART\n",
            "have -- AUX\n",
            "found -- VERB\n",
            "this -- DET\n",
            "used -- VERB\n",
            "( -- PUNCT\n",
            "phone -- NOUN\n",
            "to -- ADP\n",
            "us -- PRON\n",
            "& -- CCONJ\n",
            "not -- PART\n",
            "used -- VERB\n",
            "hard -- ADV\n",
            "at -- ADV\n",
            "all -- ADV\n",
            ") -- PUNCT\n",
            ", -- PUNCT\n",
            "phone -- NOUN\n",
            "on -- ADP\n",
            "line -- NOUN\n",
            "from -- ADP\n",
            "someone -- PRON\n",
            "who -- PRON\n",
            "upgraded -- VERB\n",
            "and -- CCONJ\n",
            "sold -- VERB\n",
            "this -- DET\n",
            "one -- NOUN\n",
            ". -- PUNCT\n",
            "My -- PRON\n",
            "Son -- PROPN\n",
            "liked -- VERB\n",
            "his -- PRON\n",
            "old -- ADJ\n",
            "one -- NOUN\n",
            "that -- PRON\n",
            "finally -- ADV\n",
            "fell -- VERB\n",
            "apart -- ADV\n",
            "after -- ADP\n",
            "2.5 -- NUM\n",
            "+ -- NUM\n",
            "years -- NOUN\n",
            "and -- CCONJ\n",
            "did -- AUX\n",
            "n't -- PART\n",
            "want -- VERB\n",
            "an -- DET\n",
            "upgrade -- NOUN\n",
            "! -- PUNCT\n",
            "! -- PUNCT\n",
            "Thank -- VERB\n",
            "you -- PRON\n",
            "Seller -- PROPN\n",
            ", -- PUNCT\n",
            "we -- PRON\n",
            "really -- ADV\n",
            "appreciate -- VERB\n",
            "it -- PRON\n",
            "& -- CCONJ\n",
            "your -- PRON\n",
            "honesty -- NOUN\n",
            "re -- ADP\n",
            ": -- PUNCT\n",
            "said -- VERB\n",
            "used -- ADJ\n",
            "phone -- NOUN\n",
            ". -- PUNCT\n",
            "I -- PRON\n",
            "recommend -- VERB\n",
            "this -- DET\n",
            "seller -- NOUN\n",
            "very -- ADV\n",
            "highly -- ADV\n",
            "& -- CCONJ\n",
            "would -- AUX\n",
            "but -- CCONJ\n",
            "from -- ADP\n",
            "them -- PRON\n",
            "again -- ADV\n",
            "! -- PUNCT\n",
            "! -- PUNCT\n",
            "\n"
          ]
        }
      ],
      "source": [
        "review1=nlp(review1);print(review1.text); [print(f\"{token.text} -- {token.pos_}\") for token in review1];print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xOBlgcu0VAKh"
      },
      "source": [
        "#### Real world data is usually messy, observe the words `found` and `used`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "yB1t1bPTVAKh"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Lemma</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>phone</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>one</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>honesty</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>line</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>seller</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>upgrade</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>year</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         count\n",
              "Lemma         \n",
              "phone        3\n",
              "one          2\n",
              "honesty      1\n",
              "line         1\n",
              "seller       1\n",
              "upgrade      1\n",
              "year         1"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pos = [word.pos_ for word in review1]\n",
        "lemma = [word.lemma_ for word in review1]\n",
        "text = [word.text for word in review1]\n",
        "df = pd.DataFrame({'Text':text, 'Lemma':lemma, 'Pos':pos})\n",
        "#print(df['Pos'].value_counts())\n",
        "df[df['Pos']=='NOUN'].groupby(by='Lemma').agg({'Lemma':'count'}).rename(columns={'Lemma':'count'}).sort_values(by='count', ascending=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "G3LDkWepVAKi"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:07<00:00, 133.70it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6871 phone      1196\n",
            "battery      90\n",
            "time         90\n",
            "screen       87\n",
            "dtype: int64\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "df_all = pd.DataFrame()\n",
        "reviews = samsung_reviews.split(\"\\n\")[:1000]\n",
        "print(len(reviews))\n",
        "lemma = []\n",
        "for review in tqdm(reviews):\n",
        "    review=nlp(review)\n",
        "    for word in review:\n",
        "        if word.pos_ != 'NOUN': continue\n",
        "        #pos.append(word.pos_)\n",
        "        lemma.append(word.lemma_)\n",
        "        #text.append(word.text)\n",
        "        #df = pd.DataFrame({'text':text, 'lemma':lemma, 'pos':pos})\n",
        "        #df_all = pd.concat([df_all, df])\n",
        "\n",
        "#print(df_all.shape)\n",
        "#df_all.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6871\n",
            "phone      1196\n",
            "battery      90\n",
            "time         90\n",
            "screen       87\n",
            "price        86\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "lemma_ = pd.Series(data=lemma)\n",
        "print(len(lemma_));print(lemma_.value_counts()[:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-uR8q-LVAKi"
      },
      "source": [
        "#### It seems possible that if we extract all the nouns from the reviews and look at the top 5 most frequent lemmatised noun forms, we will be able to identify `What people are talking about?`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOvqBuwgVAKj"
      },
      "source": [
        "### Lets repeat this experiment on a larger set of reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RsDUv3X1VAKj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lrVi3UPTVAKj"
      },
      "source": [
        "### Lets add some way of keeping track of time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zNhp_45EVAKj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jai2hnfoVAKk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94gZ5gxLVAKk"
      },
      "source": [
        "### Did you notice anything? What do you think will be the time taken to process all the reviews?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Op_ftvWyVAKk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VDMknUOXVAKl"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1PsJmzrtVAKl"
      },
      "source": [
        "## Summary\n",
        "- POS tag based rule seems to be working well\n",
        "- We need to figure out a way to reduce the time taken to process reviews"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "POS2_Commented.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
